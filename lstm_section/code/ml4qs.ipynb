{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22daa519-7043-4487-a19e-dd1ab180867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scipy.fft import fft\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8780d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training datasets\n",
    "accelerometer_train_data = pd.read_csv('/home/mzero/main/uni_repo/machine_learning_fqs_2024/ml4qs-gesture-recognition/Combined_100min_data/Combined_accelerometer_100min_with_lowpass.csv')\n",
    "gyroscope_train_data = pd.read_csv('/home/mzero/main/uni_repo/machine_learning_fqs_2024/ml4qs-gesture-recognition/Combined_100min_data/Combined_gyroscope_100min_with_lowpass.csv')\n",
    "linear_accelerometer_train_data = pd.read_csv('/home/mzero/main/uni_repo/machine_learning_fqs_2024/ml4qs-gesture-recognition/Combined_100min_data/Combined_linear_accelerometer_100min_with_lowpass.csv')\n",
    "magnetometer_train_data = pd.read_csv('/home/mzero/main/uni_repo/machine_learning_fqs_2024/ml4qs-gesture-recognition/Combined_100min_data/Combined_magnetometer_100min_with_lowpass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "961181c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test datasets\n",
    "accelerometer_test_data = pd.read_csv('/home/mzero/main/uni_repo/machine_learning_fqs_2024/ml4qs-gesture-recognition/Combined_40min_test/Combined_accelerometer_40min_with_lowpass.csv')\n",
    "gyroscope_test_data = pd.read_csv('/home/mzero/main/uni_repo/machine_learning_fqs_2024/ml4qs-gesture-recognition/Combined_40min_test/Combined_gyroscope_40min_with_lowpass.csv')\n",
    "linear_accelerometer_test_data = pd.read_csv('/home/mzero/main/uni_repo/machine_learning_fqs_2024/ml4qs-gesture-recognition/Combined_40min_test/Combined_linear_accelerometer_40min_with_lowpass.csv')\n",
    "magnetometer_test_data = pd.read_csv('/home/mzero/main/uni_repo/machine_learning_fqs_2024/ml4qs-gesture-recognition/Combined_40min_test/Combined_magnetometer_40min_with_lowpass.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850bf64",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e92e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on time and label columns - syncronizing to same time point. (train)\n",
    "train_df_1 = pd.merge(accelerometer_train_data, gyroscope_train_data, on=['time', 'label'])\n",
    "train_df_2 = pd.merge(train_df_1, linear_accelerometer_train_data, on=['time', 'label'])\n",
    "train_df_3 = pd.merge(train_df_2, magnetometer_train_data, on=['time', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bafbf1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on time and label columns - syncronizing to same time point. (test)\n",
    "test_df_1 = pd.merge(accelerometer_test_data, gyroscope_test_data, on=['time', 'label'])\n",
    "test_df_2 = pd.merge(test_df_1, linear_accelerometer_test_data, on=['time', 'label'])\n",
    "test_df_3 = pd.merge(test_df_2, magnetometer_test_data, on=['time', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "674f5374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(type(train_df_3))\n",
    "display(type(test_df_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032c8e8",
   "metadata": {},
   "source": [
    "##### Fourier Transformation --> Normalization Method: X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d51b1",
   "metadata": {},
   "source": [
    "###### Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d922222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Applying Fast Fourier Transformation - Discrete fourier Transformation\n",
    "def apply_dft(df):\n",
    "    features_X = df.columns.difference(['time', 'label'])\n",
    "    df[features_X] = np.abs(fft(df[features_X], axis=1))\n",
    "\n",
    "    return df \n",
    "\n",
    "train_df_X = apply_dft(train_df_3)\n",
    "test_df_X = apply_dft(test_df_3)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e43ced0",
   "metadata": {},
   "source": [
    "###### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "795ea4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['clapping' 'handshake' 'highfive' 'waving']\n",
      "Number of classes: 4\n",
      "Classes: ['clapping' 'handshake' 'highfive' 'waving']\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def normalizer(df):\n",
    "    # Normalize the feature columns\n",
    "    features_X = df.columns.difference(['time', 'label'])\n",
    "    scaler = StandardScaler()\n",
    "    df[features_X] = scaler.fit_transform(df[features_X])\n",
    "\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "    # Verify the unique classes\n",
    "    print(f\"Classes: {label_encoder.classes_}\")\n",
    "    print(f\"Number of classes: {label_encoder.classes_.shape[0]}\")\n",
    "\n",
    "    return df, label_encoder\n",
    "\n",
    "train_data_X, train_label_encoder = normalizer(train_df_X)\n",
    "test_data_X, test_label_encoder = normalizer(test_df_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e0cc39",
   "metadata": {},
   "source": [
    "##### Normalization -> Fourier Transformation Method: Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba0359a",
   "metadata": {},
   "source": [
    "###### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0adc6b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [0 1 2 3]\n",
      "Number of classes: 4\n",
      "Classes: [0 1 2 3]\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "source": [
    "def normalizer(df):\n",
    "    # Normalize the feature columns\n",
    "    features_Y = df.columns.difference(['time', 'label'])\n",
    "    scaler = StandardScaler()\n",
    "    df[features_Y] = scaler.fit_transform(df[features_Y])\n",
    "\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "    # Verify the unique classes\n",
    "    print(f\"Classes: {label_encoder.classes_}\")\n",
    "    print(f\"Number of classes: {label_encoder.classes_.shape[0]}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_data_Y = normalizer(train_df_3)\n",
    "test_data_Y = normalizer(test_df_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f695667",
   "metadata": {},
   "source": [
    "###### Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "542f61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Applying Fast Fourier Transformation - Discrete fourier Transformation\n",
    "def apply_dft(df):\n",
    "    features_Y = df.columns.difference(['time', 'label'])\n",
    "    df[features_Y] = np.abs(fft(df[features_Y], axis=1))\n",
    "    \n",
    "    return df \n",
    "\n",
    "train_data_Y = apply_dft(train_data_Y)\n",
    "test_data_Y = apply_dft(test_data_Y)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9870fbe",
   "metadata": {},
   "source": [
    "### Long Short-term Memory Model Implimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4cf620",
   "metadata": {},
   "source": [
    "###### Manual Method: Creating sequence and sorting data: method Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "466e78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example feature columns and label column\n",
    "# features = train_data_Y.columns.difference(['time', 'label'])\n",
    "\n",
    "# # Prepare training data\n",
    "# time_steps = 50  # Number of time steps to look back\n",
    "# X_train = []\n",
    "# y_train = []\n",
    "\n",
    "# for i in range(time_steps, len(train_data_X)):\n",
    "#     X_train.append(train_data_Y.iloc[i-time_steps:i][features].values)\n",
    "#     y_train.append(train_data_Y.iloc[i]['label'])\n",
    "\n",
    "# X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# # Prepare test data\n",
    "# X_test = []\n",
    "# y_test = []\n",
    "\n",
    "# for i in range(time_steps, len(test_data_X)):\n",
    "#     X_test.append(test_data_Y.iloc[i-time_steps:i][features].values)\n",
    "#     y_test.append(test_data_Y.iloc[i]['label'])\n",
    "\n",
    "# X_test, y_test = np.array(X_test), np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aced02",
   "metadata": {},
   "source": [
    "###### Manual Method: Creating sequence and sorting data: method X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6a5056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example feature columns and label column\n",
    "features = train_data_X.columns.difference(['time', 'label'])\n",
    "\n",
    "# Prepare training data\n",
    "time_steps = 50  # Number of time steps to look back\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(time_steps, len(train_data_X)):\n",
    "    X_train.append(train_data_X.iloc[i-time_steps:i][features].values)\n",
    "    y_train.append(train_data_X.iloc[i]['label'])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Prepare test data\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(time_steps, len(test_data_X)):\n",
    "    X_test.append(test_data_X.iloc[i-time_steps:i][features].values)\n",
    "    y_test.append(test_data_X.iloc[i]['label'])\n",
    "\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a38325",
   "metadata": {},
   "source": [
    "###### LSTM Model - Tenserflow & Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa577a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmPipline():\n",
    "    \"\"\"\n",
    "    This is a high-level overview of what the class does.\n",
    "\n",
    "    More detailed description if necessary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train, X_test, y_train, y_test,train_label_encoder):\n",
    "        self.train_label_encoder = None\n",
    "        self.test_label_encoder = None\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.tuner = None\n",
    "        self.best_model = None\n",
    "        self.best_configs = None\n",
    "        \n",
    "    \n",
    "\n",
    "    def model_builder(self, hp):\n",
    "        \"\"\"\n",
    "        Perform some action with param3.\n",
    "\n",
    "        Args:\n",
    "            param3 (type): Description of param3.\n",
    "\n",
    "        Returns:\n",
    "            return_type: Description of the return value.\n",
    "        \"\"\"\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=hp.Int('units', min_value=32, max_value=128, step=16), \n",
    "                    input_shape=(X_train.shape[1], X_train.shape[2])))# Tuning the number of units in the first LSTM layer\n",
    "        model.add(Dropout(rate=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1))) # Tuning the dropout rate\n",
    "        model.add(Dense(units=4, activation='softmax'))  # Output layer\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
    "                    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                    metrics=['accuracy']) # Compile the model\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    def tuner_initiator(self):\n",
    "        \"\"\"\n",
    "        Perform some action with param3.\n",
    "\n",
    "        Args:\n",
    "            param3 (type): Description of param3.\n",
    "\n",
    "        Returns:\n",
    "            return_type: Description of the return value.\n",
    "        \"\"\"\n",
    "\n",
    "        self.tuner = kt.Hyperband(\n",
    "            self.model_builder,\n",
    "            objective='val_accuracy',\n",
    "            max_epochs=50,\n",
    "            factor=3,\n",
    "            directory='/home/mzero/main/uni_repo/machine_learning_fqs_2024/ml4qs-gesture-recognition/lstm_section/results',\n",
    "            project_name='ml4qs_gesture_recognition'\n",
    "        )\n",
    "\n",
    "\n",
    "    def parameter_search(self):\n",
    "        \"\"\"\n",
    "        Perform some action with param3.\n",
    "\n",
    "        Args:\n",
    "            param3 (type): Description of param3.\n",
    "\n",
    "        Returns:\n",
    "            return_type: Description of the return value.\n",
    "        \"\"\"\n",
    "\n",
    "        self.tuner.search(self.X_train, self.y_train, epochs=50, validation_split=0.3, callbacks=[EarlyStopping(monitor='val_loss', patience=5)]) # Search for the best parameters \n",
    "        best_configs= self.tuner.get_best_hyperparameters(num_trials=1)[0]# Get the optimal hyperparameters\n",
    "\n",
    "        return best_configs\n",
    "\n",
    "\n",
    "    def output_optimimal_configs(self, best_configs):\n",
    "        \"\"\"\n",
    "        Perform some action with param3.\n",
    "\n",
    "        Args:\n",
    "            param3 (type): Description of param3.\n",
    "\n",
    "        Returns:\n",
    "            return_type: Description of the return value.\n",
    "        \"\"\"\n",
    "\n",
    "        units = best_configs.get('units')\n",
    "        dropout = best_configs.get('dropout')\n",
    "        learning_rate = best_configs.get('learning_rate')\n",
    "        optimal_epochs = best_configs.get('tuner/epochs')\n",
    "\n",
    "        print(f\"\"\"\n",
    "        Optimal hyperparameters:\n",
    "        - Units in LSTM layer: {units}\n",
    "        - Dropout rate: {dropout}\n",
    "        - Learning rate: {learning_rate}\n",
    "        - Optimal number of epochs: {optimal_epochs} \"\"\")\n",
    "\n",
    "\n",
    "    def evaluation_initiator(self):\n",
    "        num_iterations = 10\n",
    "        random_seeds = np.random.randint(0, 1000, size=num_iterations)\n",
    "\n",
    "        f1_scores = []\n",
    "\n",
    "        for seed in random_seeds:\n",
    "            f1 = self.train_evaluate_model(best_configs, X_train, y_train, X_test, y_test)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "        f1_scores = np.array(f1_scores)\n",
    "\n",
    "        return f1_score\n",
    "\n",
    "\n",
    "    def train_evaluate_model(self, best_configs, train_label_encoder):\n",
    "        \"\"\"\n",
    "        Perform some action with param3.\n",
    "\n",
    "        Args:\n",
    "            param3 (type): Description of param3.\n",
    "\n",
    "        Returns:\n",
    "            return_type: Description of the return value.\n",
    "        \"\"\"\n",
    "        # Convert label encoder classes to strings for classification report\n",
    "        target_names = [str(cls) for cls in test_label_encoder.classes_]\n",
    "        \n",
    "        \n",
    "        optimal_epochs = best_configs.get('tuner/epochs')\n",
    "\n",
    "        hypermodel = self.tuner.hypermodel.build(best_configs)\n",
    "        hypermodel.fit(self.X_train, self.y_train, epochs=optimal_epochs, validation_split=0.3)\n",
    "        y_pred_lstm = hypermodel.predict(self.X_test)\n",
    "        y_pred_classes_lstm = np.argmax(y_pred_lstm, axis=1)\n",
    "\n",
    "        accuracy_lstm = accuracy_score(self.y_test, y_pred_classes_lstm)\n",
    "        conf_matrix_lstm = confusion_matrix(self.y_test, y_pred_classes_lstm)\n",
    "        class_report_lstm = classification_report(self.y_test, y_pred_classes_lstm, target_names=target_names)\n",
    "        # f1 = f1_score(self.y_test, y_pred_lstm, average='weighted')\n",
    "\n",
    "        # Print the metrics\n",
    "        print(f\"Accuracy: {accuracy_lstm:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix_lstm)\n",
    "        print(\"Classification Report:\")\n",
    "        print(class_report_lstm)\n",
    "        print(\"F1 Score:\")\n",
    "        # print(f1)\n",
    "\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.tuner_initiator()\n",
    "        best_configs = self.parameter_search()\n",
    "        self.output_optimimal_configs(best_configs)\n",
    "        # f1_scores  = self.evaluation_initiator() # closed\n",
    "\n",
    "        # Model 1: Pre-processed Sensor Data\n",
    "        print(\"Model 1: LowPass Data\")\n",
    "        lstm_model = self.train_evaluate_model(best_configs, train_label_encoder)\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f53ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from /home/mzero/main/uni_repo/machine_learning_fqs_2024/ml4qs-gesture-recognition/lstm_section/results/ml4qs_gesture_recognition/tuner0.json\n",
      "\n",
      "        Optimal hyperparameters:\n",
      "        - Units in LSTM layer: 96\n",
      "        - Dropout rate: 0.0\n",
      "        - Learning rate: 0.0015717490429428354\n",
      "        - Optimal number of epochs: 6 \n",
      "Model 1: LowPass Data\n",
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mzero/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7437 - loss: 0.6054 - val_accuracy: 0.2390 - val_loss: 3.9786\n",
      "Epoch 2/6\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9311 - loss: 0.2002 - val_accuracy: 0.1051 - val_loss: 5.6137\n",
      "Epoch 3/6\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9708 - loss: 0.1132 - val_accuracy: 0.2074 - val_loss: 5.2077\n",
      "Epoch 4/6\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9859 - loss: 0.0563 - val_accuracy: 0.1066 - val_loss: 6.6642\n",
      "Epoch 5/6\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9918 - loss: 0.0301 - val_accuracy: 0.2188 - val_loss: 6.1687\n",
      "Epoch 6/6\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9910 - loss: 0.0333 - val_accuracy: 0.1891 - val_loss: 7.3809\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Accuracy: 0.2671\n",
      "Confusion Matrix:\n",
      "[[314 869   7   0]\n",
      " [862 235  50   0]\n",
      " [ 49 434 711   0]\n",
      " [640 535  11   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    clapping       0.17      0.26      0.21      1190\n",
      "   handshake       0.11      0.20      0.15      1147\n",
      "    highfive       0.91      0.60      0.72      1194\n",
      "      waving       0.00      0.00      0.00      1186\n",
      "\n",
      "    accuracy                           0.27      4717\n",
      "   macro avg       0.30      0.27      0.27      4717\n",
      "weighted avg       0.30      0.27      0.27      4717\n",
      "\n",
      "F1 Score:\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mzero/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mzero/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mzero/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tester = LstmPipline(X_train, X_test, y_train, y_test, train_label_encoder)\n",
    "print(tester.run())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
